<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linear algebra on The Median Data Scientist</title>
    <link>/categories/linear-algebra/</link>
    <description>Recent content in Linear algebra on The Median Data Scientist</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Tue, 08 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/linear-algebra/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Curse of Dimensionality</title>
      <link>/post/curse-of-dimensionality/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/curse-of-dimensionality/</guid>
      <description>Today, I hope to present a quick glimpse at the phenomenon called the “Curse of Dimensionality”. For this demonstration, I am simply calculating how much random data stays within two standard deviations (in the Euclidean norm) as we go from one dimension to higher dimensions.
Random DataHere are 10 vectors of 100 random numbers each sampled from the standard normal distribution stored as a matrix …
X &amp;lt;- matrix(rnorm(1000), nrow = 100, ncol = 10)… and as a data frame.</description>
    </item>
    
  </channel>
</rss>