<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data mining on The Median Data Scientist</title>
    <link>/categories/data-mining/</link>
    <description>Recent content in Data mining on The Median Data Scientist</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sat, 13 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/data-mining/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Fall Plans for American Universities</title>
      <link>/post/fall-plans-for-american-universities/</link>
      <pubDate>Sat, 13 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/fall-plans-for-american-universities/</guid>
      <description>IntroductionToday’s coding practice is based on the following article and data source (there is literally a “Get the Data” link):
Here’s a List of Colleges’ Plans for Reopening in the Falllibrary(&amp;quot;geofacet&amp;quot;)library(&amp;quot;rvest&amp;quot;)library(&amp;quot;tidyverse&amp;quot;)# load datadf_raw &amp;lt;- read_csv(&amp;quot;data-w8lLG.csv&amp;quot;)colnames(df_raw)## [1] &amp;quot;Institution&amp;quot; &amp;quot;Control&amp;quot; &amp;quot;State&amp;quot; &amp;quot;Category&amp;quot;Data Wrangling# filter out Excel artifacts (trivial, empty rows)df &amp;lt;- df_raw %&amp;gt;%filter(Institution != &amp;quot;#REF!&amp;quot;)#States as factorsstates_alphabetically &amp;lt;- sort(unique(df$State))df$State_factor &amp;lt;- factor(df$State,levels = states_alphabetically)#extracting text from urls (rvest!</description>
    </item>
    
    <item>
      <title>Analysis of NYT Sample of Covid-19 Obituaries</title>
      <link>/post/analysis-of-nyt-sample-of-covid-19-obituaries/</link>
      <pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/analysis-of-nyt-sample-of-covid-19-obituaries/</guid>
      <description>Obtaining the DataOn May 24, 2020, the New York Times published an article called “An Incalcuable Loss”
&amp;quot;America is fast approaching a grim milestone in the coronavirus outbreak — each figure here represents one of the nearly 100,000 lives lost so far. But a count reveals only so much. Memories, gathered from obituaries across the country, help us to reckon with what was lost.&amp;quot;What I am trying to do today is summarize the 1001 obituaries.</description>
    </item>
    
  </channel>
</rss>