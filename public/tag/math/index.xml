<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>math | Derek Sollberger&#39;s Blog</title>
    <link>https://dsollberger.netlify.com/tag/math/</link>
      <atom:link href="https://dsollberger.netlify.com/tag/math/index.xml" rel="self" type="application/rss+xml" />
    <description>math</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 13 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dsollberger.netlify.com/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>math</title>
      <link>https://dsollberger.netlify.com/tag/math/</link>
    </image>
    
    <item>
      <title>Duolingo Leagues</title>
      <link>https://dsollberger.netlify.com/post/duolingo-leagues/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://dsollberger.netlify.com/post/duolingo-leagues/</guid>
      <description>


&lt;p&gt;&lt;code&gt;Duolingo&lt;/code&gt;, the language learning app, places users in groups of 50 and assigns a &lt;code&gt;league&lt;/code&gt; to each user to encourage competition. The leagues are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bronze, Silver, Gold, Sapphire, Ruby, Emerald, Amethyst, Pearl, Obsidian, and Diamond (in that increasing order)&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;what-proportion-of-duolingo-users-are-in-each-league&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What proportion of Duolingo users are in each league?&lt;/h1&gt;
&lt;p&gt;The rules are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;everyone starts in the Bronze League&lt;/li&gt;
&lt;li&gt;the top 15 percent of each group gets promoted to the next league up (measured weekly)&lt;/li&gt;
&lt;li&gt;the bottom 10 percent of each group is related downward&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this post, I will try out some stochastic processes calculations to answer that question.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;leagues &amp;lt;- c(&amp;quot;Bronze&amp;quot;, &amp;quot;Silver&amp;quot;, &amp;quot;Gold&amp;quot;, &amp;quot;Sapphire&amp;quot;, &amp;quot;Ruby&amp;quot;,
             &amp;quot;Emerald&amp;quot;, &amp;quot;Amethyst&amp;quot;, &amp;quot;Pearl&amp;quot;, &amp;quot;Obsidian&amp;quot;, &amp;quot;Diamond&amp;quot;)

transition_matrix &amp;lt;- matrix( rep(0, 100), 10)

# trying shortcuts
diag(transition_matrix[-10,-1]) &amp;lt;- 15 #top 15 percent of each group gets promoted
diag(transition_matrix[-1,-10]) &amp;lt;- 10 #bottom 10 percent of each group is relegated
diag(transition_matrix)         &amp;lt;- 75 #the rest stay where they are

# fix the corners
transition_matrix[1,1]    &amp;lt;- 85
transition_matrix[10, 10] &amp;lt;- 85

# make row-stochastic (i.e. so each row adds up to one)
transition_matrix &amp;lt;- transition_matrix/100

# R allows user to label rows and columns
rownames(transition_matrix) &amp;lt;- leagues
colnames(transition_matrix) &amp;lt;- leagues

print(transition_matrix)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          Bronze Silver Gold Sapphire Ruby Emerald Amethyst Pearl Obsidian
## Bronze     0.85   0.15 0.00     0.00 0.00    0.00     0.00  0.00     0.00
## Silver     0.10   0.75 0.15     0.00 0.00    0.00     0.00  0.00     0.00
## Gold       0.00   0.10 0.75     0.15 0.00    0.00     0.00  0.00     0.00
## Sapphire   0.00   0.00 0.10     0.75 0.15    0.00     0.00  0.00     0.00
## Ruby       0.00   0.00 0.00     0.10 0.75    0.15     0.00  0.00     0.00
## Emerald    0.00   0.00 0.00     0.00 0.10    0.75     0.15  0.00     0.00
## Amethyst   0.00   0.00 0.00     0.00 0.00    0.10     0.75  0.15     0.00
## Pearl      0.00   0.00 0.00     0.00 0.00    0.00     0.10  0.75     0.15
## Obsidian   0.00   0.00 0.00     0.00 0.00    0.00     0.00  0.10     0.75
## Diamond    0.00   0.00 0.00     0.00 0.00    0.00     0.00  0.00     0.10
##          Diamond
## Bronze      0.00
## Silver      0.00
## Gold        0.00
## Sapphire    0.00
## Ruby        0.00
## Emerald     0.00
## Amethyst    0.00
## Pearl       0.00
## Obsidian    0.15
## Diamond     0.85&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Knowing some about stochastic processes, we can either implement an initial distribution and employ matrix-vector multiplication over many iterations, or we can find an eigenvector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;findStatDist &amp;lt;- function(P){
  # This function will compute the stationary distribution for a transition matrix
  # Input: row-stochastic matrix P
  # Output: row vector pi_vec
  
  # obtain left-eigenvector for lambda = 1
  x &amp;lt;- eigen(t(P))$vectors[,1] 
  
  # normalize the eigenvector in the one-norm
  pi_vec &amp;lt;- x / sum(x)
  pi_vec #return this vector
}

answer &amp;lt;- as.data.frame(round(100*findStatDist(transition_matrix)))

# R allows user to label rows and columns
rownames(answer) &amp;lt;- leagues
colnames(answer) &amp;lt;- &amp;quot;percentage&amp;quot;

print(answer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          percentage
## Bronze            3
## Silver            4
## Gold              5
## Sapphire          7
## Ruby              9
## Emerald          11
## Amethyst         13
## Pearl            15
## Obsidian         16
## Diamond          17&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Curse of Dimensionality</title>
      <link>https://dsollberger.netlify.com/post/curse-of-dimensionality/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://dsollberger.netlify.com/post/curse-of-dimensionality/</guid>
      <description>


&lt;p&gt;Today, I hope to present a quick glimpse at the phenomenon called the “Curse of Dimensionality”. For this demonstration, I am simply calculating how much random data stays within two standard deviations (in the Euclidean norm) as we go from one dimension to higher dimensions.&lt;/p&gt;
&lt;div id=&#34;random-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Random Data&lt;/h3&gt;
&lt;p&gt;Here are 10 vectors of 100 random numbers each sampled from the standard normal distribution stored as a matrix …&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- matrix(rnorm(1000), nrow = 100, ncol = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;… and as a data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(X)
head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           X1          X2          X3          X4         X5         X6
## 1  0.0256453  0.28398713  0.67057945  1.09584061  0.3824753  1.4061483
## 2 -0.6176034 -0.40257645  1.13756561 -0.25761710 -0.1488482 -0.1959629
## 3 -0.5235474 -0.68893524 -0.70737197  0.80125649  0.4926702 -1.9662689
## 4 -0.3737617  0.06833939 -0.02937106 -0.60665832  0.2656111  1.2102051
## 5 -0.9429225  0.05136859  1.89588703  0.30911255 -0.2143345 -0.2801334
## 6  0.4515558 -0.31945406 -2.42236506  0.06607036  0.3371893 -0.3928504
##             X7         X8          X9         X10
## 1  0.671601688 -1.9165923 -0.81464512  0.01496321
## 2 -0.005786507  0.2001263  1.59233921  0.53711798
## 3 -0.712297275  0.8505601 -2.58287100  1.04165643
## 4  0.892004771 -1.0628529  0.37102924  0.19434494
## 5 -1.365184181  0.3970239  0.08127754  2.02421067
## 6  0.746595767 -1.1335422 -0.54150029 -0.56877836&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;one-dimension&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;One Dimension&lt;/h3&gt;
&lt;p&gt;For normally distributed data, we expect that about 95% of data falls within two standard deviations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x1 &amp;lt;- X[,1]
within2sd &amp;lt;- abs(x1) &amp;lt;= 2
df1 &amp;lt;- data.frame(x1, within2sd)
mean(within2sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.96&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, 96 percent of the data in the first vector is within two standard deviations of the mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
df1 %&amp;gt;% 
  ggplot(aes(x = x1, , y = 0, color = within2sd)) +
  geom_point() + 
  labs(title = &amp;quot;One Dimension of Normal Distribution Data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dsollberger.netlify.com/post/2019-01-08-curse-of-dimensionality_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-dimensions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Two Dimensions&lt;/h3&gt;
&lt;p&gt;However, when we go into two or more dimensions, the colloquial “95%” expection starts to fade. To aid calculations, the &lt;code&gt;row_norms&lt;/code&gt; function in the &lt;code&gt;slam&lt;/code&gt; package uses the Euclidean norm by default. To aid visualization, we will use a helper function (found on Stack Overflow at &lt;a href=&#34;https://stackoverflow.com/questions/6862742/draw-a-circle-with-ggplot2&#34; class=&#34;uri&#34;&gt;https://stackoverflow.com/questions/6862742/draw-a-circle-with-ggplot2&lt;/a&gt;) to draw one circle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(slam)
within2sd &amp;lt;- row_norms(X[,1:2]) &amp;lt;= 2

gg_circle &amp;lt;- function(r = 1, xc = 0, yc = 0, color=&amp;quot;black&amp;quot;, fill=NA, ...) {
    x &amp;lt;- xc + r*cos(seq(0, pi, length.out=100))
    ymax &amp;lt;- yc + r*sin(seq(0, pi, length.out=100))
    ymin &amp;lt;- yc + r*sin(seq(0, -pi, length.out=100))
    annotate(&amp;quot;ribbon&amp;quot;, x=x, ymin=ymin, ymax=ymax, color=color, fill=fill, ...)
}

df2 &amp;lt;- data.frame(X[,1:2], within2sd)
df2 %&amp;gt;%
  ggplot(aes(x = X1, y = X2, color = within2sd)) +
  geom_point() + 
  gg_circle(r = 2, color = &amp;quot;red&amp;quot;) +
  coord_fixed() + 
  labs(title = &amp;quot;Two Dimensions of Normal Distribution Data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dsollberger.netlify.com/post/2019-01-08-curse-of-dimensionality_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(within2sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, 88 percent of the data in the first 2 vectors is within two standard deviations of the mean.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;higher-dimensions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Higher Dimensions&lt;/h3&gt;
&lt;p&gt;Plotting scatterplots in higher dimensions is much more complicated, but we can still perform the &lt;code&gt;norm&lt;/code&gt; calculations pretty quickly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N &amp;lt;- 10 #total number of dimensions
within2sd &amp;lt;- rep(0, N) #initialization

# one dimension
within2sd[1] &amp;lt;- mean(abs(x1) &amp;lt;= 2)

# higher dimensions
for(d in 2:N){
  within2sd[d] &amp;lt;- mean(row_norms(X[,1:d]) &amp;lt;= 2)
}

# plot
dimensions &amp;lt;- 1:N
df &amp;lt;- data.frame(dimensions, within2sd)
df %&amp;gt;%
  ggplot(aes(x = dimensions, y = within2sd)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, fill = &amp;quot;blue&amp;quot;) +
  scale_x_continuous(&amp;quot;Dimensions&amp;quot;, breaks = 1:N)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dsollberger.netlify.com/post/2019-01-08-curse-of-dimensionality_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Graduation Rates</title>
      <link>https://dsollberger.netlify.com/post/graduation-rates/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://dsollberger.netlify.com/post/graduation-rates/</guid>
      <description>


&lt;p&gt;In this post, I want to run an example of absorbing states in stochastic processes. This example is based on Example 3.29 in &lt;em&gt;Introduction to Stochastic Processes&lt;/em&gt; in R by Robert Dobrow.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data&lt;/h1&gt;
&lt;p&gt;The data I have assembled is based on &lt;a href=&#34;https://irds.ucmerced.edu/student-data&#34;&gt;IRDS reports&lt;/a&gt; from my own University of California at Merced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# weights
weights &amp;lt;- c(20, 70, 0, 0, 10, 0, 
       0, 5, 89, 0, 6, 0, 
       0, 0, 3, 94, 3, 0, 
       0, 0, 0, 24, 1, 76, 
       0, 0, 0, 0, 100, 0, 
       0, 0, 0, 0, 0, 100)
sparse_weights &amp;lt;- weights[weights &amp;gt; 0]

# transition matrix (row stochastic)
P &amp;lt;- matrix(weights, nrow = 6, byrow = TRUE)*0.01

# states
rownames(P) &amp;lt;- c(&amp;quot;Freshman&amp;quot;, &amp;quot;Sophomore&amp;quot;, &amp;quot;Junior&amp;quot;, &amp;quot;Senior&amp;quot;, &amp;quot;Dropped&amp;quot;, &amp;quot;Graduated&amp;quot;)
colnames(P) &amp;lt;- c(&amp;quot;Freshman&amp;quot;, &amp;quot;Sophomore&amp;quot;, &amp;quot;Junior&amp;quot;, &amp;quot;Senior&amp;quot;, &amp;quot;Dropped&amp;quot;, &amp;quot;Graduated&amp;quot;)
P&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Freshman Sophomore Junior Senior Dropped Graduated
## Freshman       0.2      0.70   0.00   0.00    0.10      0.00
## Sophomore      0.0      0.05   0.89   0.00    0.06      0.00
## Junior         0.0      0.00   0.03   0.94    0.03      0.00
## Senior         0.0      0.00   0.00   0.24    0.01      0.76
## Dropped        0.0      0.00   0.00   0.00    1.00      0.00
## Graduated      0.0      0.00   0.00   0.00    0.00      1.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This formulation assumes that about 10 percent of students drop after the first year, and about 24 percent of seniors continue to take classes into the fifth year or more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;network-graph&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Network Graph&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(igraph)
network &amp;lt;- graph_from_adjacency_matrix(P, mode = &amp;quot;directed&amp;quot;, weighted = TRUE)
plot(network,
     edge.arrow.size = 0.5,
     edge.color = &amp;quot;#D4AE00&amp;quot;,
     edge.label = sparse_weights,
     layout = layout_in_circle(network))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://dsollberger.netlify.com/post/2019-01-08-graduation-rates_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;absorbing-states&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Absorbing States&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# canonical form
Q &amp;lt;- P[1:4, 1:4]
R &amp;lt;- P[1:4, 5:6]

# fundamental matrix (inverse of (I - Q))
fundamental_matrix &amp;lt;- solve(diag(4) - Q)

# absorption
absorption &amp;lt;- fundamental_matrix %*% R
round(100*absorption)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Dropped Graduated
## Freshman       22        79
## Sophomore      10        91
## Junior          4        97
## Senior          1       100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model predicts that, starting with incoming students, about 79 percent of those students will eventually graduate while about 21 percent will eventually drop from UC Merced enrollment.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
