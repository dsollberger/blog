---
title: Degree-One Polynomials
author: Derek Sollberger
date: '2018-09-30'
slug: degree-one-polynomials
categories:
  - R
tags:
  - regression
header:
  caption: ''
  image: ''
---



<div id="problem" class="section level2">
<h2>Problem</h2>
<p>The question that one of my teaching assistants posed was “What is the difference between <code>lm(y ~ x)</code> and <code>lm(y ~ (poly,1))</code> for linear regression in R?” That is, it is quickly apparent that those commands produce different results, but for the same intention. Here I will try to explore the underlying difference.</p>
<p>Disclaimer: I know that the following discussion is incomplete. These are simply notes that I threw together overnight.</p>
</div>
<div id="exposition" class="section level2">
<h2>Exposition</h2>
<p>For a quick study, we can observe that the commands <code>lm(y ~ x)</code> and <code>lm(y ~ (poly,1))</code> produce different results:</p>
<pre class="r"><code># 50 ordered pairs of random numbers
x &lt;- runif(50)
y &lt;- runif(50, -3, 3)

# first linear model
lm1 &lt;- lm(y ~ x)

# second linear model
lm2 &lt;- lm(y ~ poly(x, 1))

# found coefficients
lm1</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##    -0.03135     -0.37976</code></pre>
<pre class="r"><code>lm2</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ poly(x, 1))
## 
## Coefficients:
## (Intercept)   poly(x, 1)  
##     -0.2030      -0.7187</code></pre>
<pre class="r"><code># plot
plot(x,y, main = &quot;quick scatterplot and linear regression&quot;)
points(mean(x), mean(y), col = &quot;purple&quot;, pch = 8)
abline(lm1, col = &quot;red&quot;, lwd = 3)
abline(lm2, col = &quot;blue&quot;, lwd = 3)
legend(0.5, 2, 
       c(&quot;lm(y ~ x)&quot;, &quot;lm(y ~ poly(x, 1))&quot;),
       col = c(&quot;red&quot;, &quot;blue&quot;),
       lwd = c(3,3))</code></pre>
<p><img src="/post/2018-09-30-degree-one-polynomials_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We observe that <code>lm(y ~ x)</code> goes though the sample means <span class="math inline">\((\bar{x}, \bar{y})\)</span>, while <code>lm(y ~ (poly,1))</code> does not. Oddly enough, if we apply a metric such as the coefficient of determination (<span class="math inline">\(R^{2}\)</span>), then the model metrics are the same!</p>
<pre class="r"><code>summary(lm1)$adj.r.squared</code></pre>
<pre><code>## [1] -0.01688544</code></pre>
<pre class="r"><code>summary(lm2)$adj.r.squared</code></pre>
<pre><code>## [1] -0.01688544</code></pre>
</div>
<div id="orthogonal-polynomials" class="section level2">
<h2>Orthogonal Polynomials</h2>
<p>Some searches on the web point toward how the <code>poly</code> command uses <a href="https://mathoverflow.net/questions/38864/visualizing-orthogonal-polynomials">othogonal polynomials</a> by default. That is, modeling with <span class="math display">\[\hat{y} = a + bx + cx^{2} + ...\]</span> is easy to interpret, higher degree terms will not add much to the predictive ability for our regression models (e.g. <span class="math inline">\(x^7\)</span> and <span class="math inline">\(x^8\)</span> are “too close” within some interval). Side note: with the <span class="math display">\[{1, x, x^{2}, ...}\]</span> basis, we learn that the <a href="https://math.stackexchange.com/questions/2211054/condition-number-for-polynomial-interpolation-matrix">Vandermonde matrix</a> for this basis has a <em>high condition number</em> and calculations with this route are <em>ill-conditioned</em>.</p>
</div>
<div id="coefficients-of-orthogonal-polynomials" class="section level2">
<h2>Coefficients of Orthogonal Polynomials</h2>
<p>There has been a <a href="https://stackoverflow.com/questions/39031172/how-poly-generates-orthogonal-polynomials-how-to-understand-the-coefs-ret">lot of discussion</a> about how <code>poly</code> works and its internal and recursive algorithm to produce a set of orthogonal polynomials over an interval of values. Here I hope to produce a simple example where we can follow the numbers.</p>
<pre class="r"><code>x &lt;- 1:5       # mean is 3
y &lt;- 15*x + 18 # line of slope 15 and y-intercept 18</code></pre>
<p>Using the <code>lm</code> command quickly recovers the slope and intercept</p>
<pre class="r"><code>lm_raw &lt;- lm(y ~ x)
lm_raw</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##          18           15</code></pre>
<p>However, the route with orthogonal polynomials yields different coefficients.</p>
<pre class="r"><code>lm_orth &lt;- lm(y ~ poly(x,1))
lm_orth</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ poly(x, 1))
## 
## Coefficients:
## (Intercept)   poly(x, 1)  
##       63.00        47.43</code></pre>
<p>We can <a href="https://stackoverflow.com/questions/26728289/extracting-orthogonal-polynomial-coefficients-from-rs-poly-function">extract the coefficents</a> from the orthogonal polynomial route, along with some normalization factors.</p>
<pre class="r"><code>a &lt;- attributes(poly(x,1))$coefs$alpha
a</code></pre>
<pre><code>## [1] 3</code></pre>
<pre class="r"><code>n &lt;- attributes(poly(x,1))$coefs$norm2
n</code></pre>
<pre><code>## [1]  1  5 10</code></pre>
</div>
<div id="building-orthogonal-polynomials" class="section level2">
<h2>Building Orthogonal Polynomials</h2>
<p>There are several ways to build orthogonal polynomials, and here I will try out the <a href="http://www.math.tamu.edu/~yvorobet/MATH304-503/Lect4-04web.pdf">Gram-Schmidt process</a>. For the base case, <span class="math display">\[p_{0} := 1\]</span> The degree-one term is <span class="math display">\[p_{1}(x) = x - \frac{&lt;x, p_{0}&gt;}{&lt;p_{0}, p_{0}&gt;} = x - \frac{\int_{1}^{5} \! x \, dx}{\int_{1}^{5} \, dx} = x - 3\]</span></p>
<p>Note that <span class="math inline">\(p_{1}(x) = x - 3\)</span> is centered at the mean <span class="math inline">\(\bar{x} = 3\)</span>.</p>
<p>Combining the coefficients found from <code>lm(y ~ poly(x,1))</code> and a normalization factor from above, we get</p>
<p><span class="math display">\[\hat{y} = 63 + 47.43 \cdot \frac{x - 3}{\sqrt{10}}\]</span></p>
<p>which is indeed <span class="math inline">\(\hat{y} = 18 + 15x\)</span> when simplified (up to rounding error, too much hand-waving, and a missing number).</p>
</div>
<div id="sources" class="section level2">
<h2>Sources</h2>
<p><a href="https://mathoverflow.net/questions/38864/visualizing-orthogonal-polynomials" class="uri">https://mathoverflow.net/questions/38864/visualizing-orthogonal-polynomials</a></p>
<p><a href="https://math.stackexchange.com/questions/2211054/condition-number-for-polynomial-interpolation-matrix" class="uri">https://math.stackexchange.com/questions/2211054/condition-number-for-polynomial-interpolation-matrix</a></p>
<p><a href="https://stackoverflow.com/questions/39031172/how-poly-generates-orthogonal-polynomials-how-to-understand-the-coefs-ret" class="uri">https://stackoverflow.com/questions/39031172/how-poly-generates-orthogonal-polynomials-how-to-understand-the-coefs-ret</a></p>
<p><a href="https://stackoverflow.com/questions/26728289/extracting-orthogonal-polynomial-coefficients-from-rs-poly-function" class="uri">https://stackoverflow.com/questions/26728289/extracting-orthogonal-polynomial-coefficients-from-rs-poly-function</a></p>
<p><a href="http://www.math.tamu.edu/~yvorobet/MATH304-503/Lect4-04web.pdf" class="uri">http://www.math.tamu.edu/~yvorobet/MATH304-503/Lect4-04web.pdf</a></p>
</div>
